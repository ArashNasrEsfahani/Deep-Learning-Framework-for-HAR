 
# A Deep Learning Framework for Human Activity Recognition*

[![Python](https://img.shields.io/badge/python-3.8%2B-blue)](https://www.python.org/)

---

## ğŸ“‘ Table of Contents
- [ğŸŒŸ Overview](#-overview)  
- [âœ¨ Features](#-features)  
- [ğŸ“‚ Datasets](#-datasets)  
- [ğŸ—ï¸ Model Architectures](#ï¸-model-architectures)  
- [ğŸ“Š Results](#-results)  

---

## ğŸŒŸ Overview
This repo contatins notebook for HAR that are modular, endâ€‘toâ€‘end pipeline for human activity recognition (HAR) using wearable sensor data. They implement and benchmark four architectures to extract both spatial and temporal features, plus attention mechanisms for refined performance.

---

## âœ¨ Features
- **Flexible Preprocessing**: normalization, segmentation & class balancing  
- **Plugâ€‘andâ€‘Play Models**: easily switch between LSTM, attention, CNNâ€“LSTM, and hybrid designs  
- **Training Utilities**: configurable epochs, early stopping & checkpointing  
- **Evaluation Tools**: accuracy metrics, confusion matrices & classification reports  
- **Reproducible Notebooks**: ready for Google Colab experiments  

---

## ğŸ“‚ Datasets
1. **UCIâ€‘HAR**  
   - 30 subjects, 6 activities, 561 features  
   - Preâ€‘segmented into train/test  
2. **MHEALTH**  
   - 10 subjects, originally 12 â†’ filtered to 4 activities  
   - Scripts handle 70/15/15 split & balancing  

Place your CSVs under `data/uci_har/` and `data/mhealth/` before running.

---

## ğŸ—ï¸ Model Architectures
- **LSTM**  
  Two-layer LSTM (128 â†’ 64 units) with dropout  
- **LSTM + Selfâ€‘Attention**  
  LSTM â†’ attention â†’ LSTM â†’ dropout  
- **CNN + LSTM + Selfâ€‘Attention**  
  Two 1D conv layers â†’ LSTM â†’ attention  
- **Stateâ€‘ofâ€‘theâ€‘Art Hybrid**  
  Residual 1D conv blocks â†’ Biâ€‘LSTM â†’ multiâ€‘head attention  

Full definitions live in the `models/` folder.

---

## ğŸ“Š Results

| Dataset   | Model                         | Accuracy (%) |
|-----------|-------------------------------|-------------:|
| **UCIâ€‘HAR** | LSTM                          |        93.76 |
|           | LSTM + Attention              |        94.40 |
|           | CNN + LSTM + Attention        |        94.91 |
|           | **Stateâ€‘ofâ€‘theâ€‘Art Hybrid**   |   **95.24**  |
| **MHEALTH** | LSTM                          |        97.98 |
|           | LSTM + Attention              |        98.24 |
|           | CNN + LSTM + Attention        |        98.01 |
|           | **Stateâ€‘ofâ€‘theâ€‘Art Hybrid**   |   **97.93**  |


